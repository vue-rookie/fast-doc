# 介绍

## 什么是 fast-code 中转站？

fast-code 中转站是一个 **统一的大模型 API 接入层**。

它并不提供模型能力本身，而是作为应用与各大模型官方 API 之间的中间层，负责 **协议适配、稳定性增强、鉴权与用量管理**，让上层应用只需关注业务逻辑本身。

通过一次接入，你可以在不修改业务代码的前提下，灵活使用或切换多种大模型服务。

---

## fast-code中转站解决了哪些问题？

在实际工程中，直接对接官方模型 API，往往会遇到以下问题：

- 接口协议不统一（OpenAI / Claude / Gemini 各一套）
- 模型版本频繁更新，升级成本高
- 网络与稳定性不可控，请求偶发失败
- 官方 API Key 暴露风险高，难以权限隔离
- 成本与用量不可观测，无法按项目统计

fast-code中转站的目标，是将这些复杂性 **集中在中间层一次性解决**。

---

## fast-code中转站能做什么？

使用fast-code中转站，你可以获得：

- **统一的 API 规范**
  - 兼容 OpenAI `/v1/chat/completions` 风格接口
  - 或使用模型原生接口（如 Gemini 原生格式）
- **模型可插拔**
  - 在不修改调用代码的情况下切换底层模型
- **Key 与权限隔离**
  - 不暴露官方 API Key
  - 支持按项目 / 用户分配独立 Key
- **稳定性增强**
  - 请求重试、超时控制、失败降级
- **用量与成本统计**
  - 按模型、Key、项目统计 Token 与请求量
- **工程化友好**
  - 可用于前端、后端、脚本、自动化工具、IDE 插件

---

## fast-code中转站适合谁？

- 前端 / 后端开发者
- AI 应用、AI 助手、自动化工具开发者
- 使用 Claude Code、CodeX、n8n 等工具的用户
- 希望长期维护项目、降低模型接入成本的人或团队

如果你已经写过一层 `llmClient`、`aiService` 或模型适配器，那么你会很容易理解fast-code存在的意义。

---

## 设计理念

- **稳定优先**：尽量贴近官方行为，避免不可控魔改  
- **工程优先**：为真实生产环境设计，而非 Demo  
- **低耦合**：模型随时可替换，业务不受影响  
- **透明可控**：调用路径、用量、成本可追踪  

中转站不是黑盒，而是一个 **可被理解、可被维护、可被替换的工程组件**。

---

## 一句话总结

> **fast-code 中转站 = 大模型世界里的 API 网关 + 协议适配层**

---
